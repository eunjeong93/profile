{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import make_scorer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from polars import col\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GroupKFold, KFold\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from xgboost import XGBClassifier\n",
    "from itertools import combinations\n",
    "import math\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.read_csv('train_labels.csv')\n",
    "targets['session'] = targets.session_id.apply(lambda x: int(x.split('_')[0]))\n",
    "targets['q'] = targets.session_id.apply(lambda x: int(x.split('_')[-1][1:]))\n",
    "\n",
    "\n",
    "columns = [\n",
    "    pl.col(\"page\").cast(pl.Float32),\n",
    "    (\n",
    "        (pl.col(\"elapsed_time\") - pl.col(\"elapsed_time\").shift(1))\n",
    "        .fill_null(0)\n",
    "        .clip(0, 1e9)\n",
    "        .over([\"session_id\", \"level\"])\n",
    "        .alias(\"elapsed_time_diff\")\n",
    "    ),\n",
    "    (\n",
    "        (pl.col(\"screen_coor_x\") - pl.col(\"screen_coor_x\").shift(1))\n",
    "        .abs()\n",
    "        .over([\"session_id\", \"level\"])\n",
    "    ),\n",
    "    (\n",
    "        (pl.col(\"screen_coor_y\") - pl.col(\"screen_coor_y\").shift(1))\n",
    "        .abs()\n",
    "        .over([\"session_id\", \"level\"])\n",
    "    ),\n",
    "    pl.col(\"fqid\").fill_null(\"fqid_None\"),\n",
    "    pl.col(\"text_fqid\").fill_null(\"text_fqid_None\")\n",
    "\n",
    "]\n",
    "df = (pl.read_parquet('train.parquet')\n",
    "\n",
    "      .with_columns(columns))\n",
    "\n",
    "\n",
    "CATS = ['event_name', 'name', 'fqid', 'room_fqid', 'text_fqid']\n",
    "NUMS = ['page', 'room_coor_x', 'room_coor_y', 'screen_coor_x', 'screen_coor_y',\n",
    "        'hover_duration', 'elapsed_time_diff']\n",
    "fqid_lists = ['worker', 'archivist', 'gramps', 'wells', 'toentry', 'confrontation', 'crane_ranger', 'groupconvo', 'flag_girl', 'tomap', 'tostacks', 'tobasement', 'archivist_glasses', 'boss', 'journals', 'seescratches', 'groupconvo_flag', 'cs', 'teddy', 'expert', 'businesscards', 'ch3start', 'tunic.historicalsociety', 'tofrontdesk', 'savedteddy', 'plaque', 'glasses', 'tunic.drycleaner', 'reader_flag', 'tunic.library', 'tracks', 'tunic.capitol_2', 'trigger_scarf', 'reader', 'directory', 'tunic.capitol_1', 'journals.pic_0.next', 'unlockdoor', 'tunic', 'what_happened', 'tunic.kohlcenter', 'tunic.humanecology', 'colorbook', 'logbook', 'businesscards.card_0.next', 'journals.hub.topics', 'logbook.page.bingo', 'journals.pic_1.next', 'journals_flag', 'reader.paper0.next', 'tracks.hub.deer', 'reader_flag.paper0.next', 'trigger_coffee', 'wellsbadge', 'journals.pic_2.next', 'tomicrofiche', 'journals_flag.pic_0.bingo', 'plaque.face.date', 'notebook', 'tocloset_dirty', 'businesscards.card_bingo.bingo', 'businesscards.card_1.next', 'tunic.wildlife', 'tunic.hub.slip', 'tocage', 'journals.pic_2.bingo', 'tocollectionflag', 'tocollection', 'chap4_finale_c',\n",
    "              'chap2_finale_c', 'lockeddoor', 'journals_flag.hub.topics', 'tunic.capitol_0', 'reader_flag.paper2.bingo', 'photo', 'tunic.flaghouse', 'reader.paper1.next', 'directory.closeup.archivist', 'intro', 'businesscards.card_bingo.next', 'reader.paper2.bingo', 'retirement_letter', 'remove_cup', 'journals_flag.pic_0.next', 'magnify', 'coffee', 'key', 'togrampa', 'reader_flag.paper1.next', 'janitor', 'tohallway', 'chap1_finale', 'report', 'outtolunch', 'journals_flag.hub.topics_old', 'journals_flag.pic_1.next', 'reader.paper2.next', 'chap1_finale_c', 'reader_flag.paper2.next', 'door_block_talk', 'journals_flag.pic_1.bingo', 'journals_flag.pic_2.next', 'journals_flag.pic_2.bingo', 'block_magnify', 'reader.paper0.prev', 'block', 'reader_flag.paper0.prev', 'block_0', 'door_block_clean', 'reader.paper2.prev', 'reader.paper1.prev', 'doorblock', 'tocloset', 'reader_flag.paper2.prev', 'reader_flag.paper1.prev', 'block_tomap2', 'journals_flag.pic_0_old.next', 'journals_flag.pic_1_old.next', 'block_tocollection', 'block_nelson', 'journals_flag.pic_2_old.next', 'block_tomap1', 'block_badge', 'need_glasses', 'block_badge_2', 'fox', 'block_1']\n",
    "DIALOGS = ['that', 'this', 'it', 'you',\n",
    "           'flag', 'can', 'and', 'is', 'the', 'to']\n",
    "name_feature = ['basic', 'undefined', 'close', 'open', 'prev', 'next']\n",
    "event_name_feature = ['cutscene_click', 'person_click', 'navigate_click',\n",
    "                      'observation_click', 'notification_click', 'object_click',\n",
    "                      'object_hover', 'map_hover', 'map_click', 'checkpoint',\n",
    "                      'notebook_click']\n",
    "text_lists = ['tunic.historicalsociety.cage.confrontation', 'tunic.wildlife.center.crane_ranger.crane', 'tunic.historicalsociety.frontdesk.archivist.newspaper', 'tunic.historicalsociety.entry.groupconvo', 'tunic.wildlife.center.wells.nodeer', 'tunic.historicalsociety.frontdesk.archivist.have_glass', 'tunic.drycleaner.frontdesk.worker.hub', 'tunic.historicalsociety.closet_dirty.gramps.news', 'tunic.humanecology.frontdesk.worker.intro', 'tunic.historicalsociety.frontdesk.archivist_glasses.confrontation', 'tunic.historicalsociety.basement.seescratches', 'tunic.historicalsociety.collection.cs', 'tunic.flaghouse.entry.flag_girl.hello', 'tunic.historicalsociety.collection.gramps.found', 'tunic.historicalsociety.basement.ch3start', 'tunic.historicalsociety.entry.groupconvo_flag', 'tunic.library.frontdesk.worker.hello', 'tunic.library.frontdesk.worker.wells', 'tunic.historicalsociety.collection_flag.gramps.flag', 'tunic.historicalsociety.basement.savedteddy', 'tunic.library.frontdesk.worker.nelson', 'tunic.wildlife.center.expert.removed_cup', 'tunic.library.frontdesk.worker.flag', 'tunic.historicalsociety.frontdesk.archivist.hello', 'tunic.historicalsociety.closet.gramps.intro_0_cs_0', 'tunic.historicalsociety.entry.boss.flag', 'tunic.flaghouse.entry.flag_girl.symbol', 'tunic.historicalsociety.closet_dirty.trigger_scarf', 'tunic.drycleaner.frontdesk.worker.done', 'tunic.historicalsociety.closet_dirty.what_happened', 'tunic.wildlife.center.wells.animals', 'tunic.historicalsociety.closet.teddy.intro_0_cs_0', 'tunic.historicalsociety.cage.glasses.afterteddy', 'tunic.historicalsociety.cage.teddy.trapped', 'tunic.historicalsociety.cage.unlockdoor', 'tunic.historicalsociety.stacks.journals.pic_2.bingo', 'tunic.historicalsociety.entry.wells.flag', 'tunic.humanecology.frontdesk.worker.badger', 'tunic.historicalsociety.stacks.journals_flag.pic_0.bingo', 'tunic.historicalsociety.closet.intro', 'tunic.historicalsociety.closet.retirement_letter.hub', 'tunic.historicalsociety.entry.directory.closeup.archivist', 'tunic.historicalsociety.collection.tunic.slip', 'tunic.kohlcenter.halloffame.plaque.face.date', 'tunic.historicalsociety.closet_dirty.trigger_coffee', 'tunic.drycleaner.frontdesk.logbook.page.bingo', 'tunic.library.microfiche.reader.paper2.bingo', 'tunic.kohlcenter.halloffame.togrampa', 'tunic.capitol_2.hall.boss.haveyougotit', 'tunic.wildlife.center.wells.nodeer_recap', 'tunic.historicalsociety.cage.glasses.beforeteddy', 'tunic.historicalsociety.closet_dirty.gramps.helpclean', 'tunic.wildlife.center.expert.recap', 'tunic.historicalsociety.frontdesk.archivist.have_glass_recap', 'tunic.historicalsociety.stacks.journals_flag.pic_1.bingo', 'tunic.historicalsociety.cage.lockeddoor', 'tunic.historicalsociety.stacks.journals_flag.pic_2.bingo', 'tunic.historicalsociety.collection.gramps.lost', 'tunic.historicalsociety.closet.notebook', 'tunic.historicalsociety.frontdesk.magnify', 'tunic.humanecology.frontdesk.businesscards.card_bingo.bingo',\n",
    "              'tunic.wildlife.center.remove_cup', 'tunic.library.frontdesk.wellsbadge.hub', 'tunic.wildlife.center.tracks.hub.deer', 'tunic.historicalsociety.frontdesk.key', 'tunic.library.microfiche.reader_flag.paper2.bingo', 'tunic.flaghouse.entry.colorbook', 'tunic.wildlife.center.coffee', 'tunic.capitol_1.hall.boss.haveyougotit', 'tunic.historicalsociety.basement.janitor', 'tunic.historicalsociety.collection_flag.gramps.recap', 'tunic.wildlife.center.wells.animals2', 'tunic.flaghouse.entry.flag_girl.symbol_recap', 'tunic.historicalsociety.closet_dirty.photo', 'tunic.historicalsociety.stacks.outtolunch', 'tunic.library.frontdesk.worker.wells_recap', 'tunic.historicalsociety.frontdesk.archivist_glasses.confrontation_recap', 'tunic.capitol_0.hall.boss.talktogramps', 'tunic.historicalsociety.closet.photo', 'tunic.historicalsociety.collection.tunic', 'tunic.historicalsociety.closet.teddy.intro_0_cs_5', 'tunic.historicalsociety.closet_dirty.gramps.archivist', 'tunic.historicalsociety.closet_dirty.door_block_talk', 'tunic.historicalsociety.entry.boss.flag_recap', 'tunic.historicalsociety.frontdesk.archivist.need_glass_0', 'tunic.historicalsociety.entry.wells.talktogramps', 'tunic.historicalsociety.frontdesk.block_magnify', 'tunic.historicalsociety.frontdesk.archivist.foundtheodora', 'tunic.historicalsociety.closet_dirty.gramps.nothing', 'tunic.historicalsociety.closet_dirty.door_block_clean', 'tunic.capitol_1.hall.boss.writeitup', 'tunic.library.frontdesk.worker.nelson_recap', 'tunic.library.frontdesk.worker.hello_short', 'tunic.historicalsociety.stacks.block', 'tunic.historicalsociety.frontdesk.archivist.need_glass_1', 'tunic.historicalsociety.entry.boss.talktogramps', 'tunic.historicalsociety.frontdesk.archivist.newspaper_recap', 'tunic.historicalsociety.entry.wells.flag_recap', 'tunic.drycleaner.frontdesk.worker.done2', 'tunic.library.frontdesk.worker.flag_recap', 'tunic.humanecology.frontdesk.block_0', 'tunic.library.frontdesk.worker.preflag', 'tunic.historicalsociety.basement.gramps.seeyalater', 'tunic.flaghouse.entry.flag_girl.hello_recap', 'tunic.historicalsociety.closet.doorblock', 'tunic.drycleaner.frontdesk.worker.takealook', 'tunic.historicalsociety.basement.gramps.whatdo', 'tunic.library.frontdesk.worker.droppedbadge', 'tunic.historicalsociety.entry.block_tomap2', 'tunic.library.frontdesk.block_nelson', 'tunic.library.microfiche.block_0', 'tunic.historicalsociety.entry.block_tocollection', 'tunic.historicalsociety.entry.block_tomap1', 'tunic.historicalsociety.collection.gramps.look_0', 'tunic.library.frontdesk.block_badge', 'tunic.historicalsociety.cage.need_glasses', 'tunic.library.frontdesk.block_badge_2', 'tunic.kohlcenter.halloffame.block_0', 'tunic.capitol_0.hall.chap1_finale_c', 'tunic.capitol_1.hall.chap2_finale_c', 'tunic.capitol_2.hall.chap4_finale_c', 'tunic.wildlife.center.fox.concern', 'tunic.drycleaner.frontdesk.block_0', 'tunic.historicalsociety.entry.gramps.hub', 'tunic.humanecology.frontdesk.block_1', 'tunic.drycleaner.frontdesk.block_1']\n",
    "room_lists = ['tunic.historicalsociety.entry', 'tunic.wildlife.center', 'tunic.historicalsociety.cage', 'tunic.library.frontdesk', 'tunic.historicalsociety.frontdesk', 'tunic.historicalsociety.stacks', 'tunic.historicalsociety.closet_dirty', 'tunic.humanecology.frontdesk', 'tunic.historicalsociety.basement',\n",
    "              'tunic.kohlcenter.halloffame', 'tunic.library.microfiche', 'tunic.drycleaner.frontdesk', 'tunic.historicalsociety.collection', 'tunic.historicalsociety.closet', 'tunic.flaghouse.entry', 'tunic.historicalsociety.collection_flag', 'tunic.capitol_1.hall', 'tunic.capitol_0.hall', 'tunic.capitol_2.hall']\n",
    "\n",
    "# 신규 생성\n",
    "event_type = ['click', 'hover']\n",
    "# 신규 생성\n",
    "total_event = event_name_feature + event_type\n",
    "\n",
    "LEVELS = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,\n",
    "          12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
    "level_groups = [\"0-4\", \"5-12\", \"13-22\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.filter(pl.col(\"level_group\") == '0-4')\n",
    "df2 = df.filter(pl.col(\"level_group\") == '5-12')\n",
    "df3 = df.filter(pl.col(\"level_group\") == '13-22')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineer(x, grp, use_extra, feature_suffix):\n",
    "    aggs = [\n",
    "        pl.col(\"index\").count().alias(f\"session_number_{feature_suffix}\"),\n",
    "\n",
    "        *[pl.col(\"fqid\").filter(pl.col(\"fqid\") == c).count().alias(f\"{c}_fqid_counts{feature_suffix}\")\n",
    "          for c in fqid_lists],\n",
    "        # *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"fqid\") == c).std().alias(f\"{c}_ET_std_{feature_suffix}\") for\n",
    "        #   c in fqid_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"fqid\") == c).mean().alias(f\"{c}_ET_mean_{feature_suffix}\") for\n",
    "          c in fqid_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"fqid\") == c).sum().alias(f\"{c}_ET_sum_{feature_suffix}\") for\n",
    "          c in fqid_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"event_type\") == c).sum().alias(f\"{c}_ET_sum_{feature_suffix}\") for\n",
    "          c in event_type],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"event_type\") == c).mean().alias(f\"{c}_ET_mean_{feature_suffix}\") for\n",
    "          c in event_type],\n",
    "        *[pl.col(\"event_type\").filter(pl.col(\"event_type\") == c).count().alias(f\"{c}_type_counts{feature_suffix}\")\n",
    "          for c in event_type],\n",
    "\n",
    "        *[pl.col(\"text_fqid\").filter(pl.col(\"text_fqid\") == c).count().alias(f\"{c}_text_fqid_counts{feature_suffix}\")\n",
    "          for\n",
    "          c in text_lists],\n",
    "        # *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text_fqid\") == c).std().alias(f\"{c}_ET_std_{feature_suffix}\") for\n",
    "        #   c in text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text_fqid\") == c).mean().alias(f\"{c}_ET_mean_{feature_suffix}\") for\n",
    "          c in text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text_fqid\") == c).sum().alias(f\"{c}_ET_sum_{feature_suffix}\") for\n",
    "          c in text_lists],\n",
    "\n",
    "        *[pl.col(\"event_name\").filter(pl.col(\"event_name\") == c).count().alias(f\"{c}_event_name_counts{feature_suffix}\")\n",
    "          for c in event_name_feature],\n",
    "        # *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"event_name\") == c).std().alias(f\"{c}_ET_std_{feature_suffix}\") for\n",
    "        #   c in event_name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"event_name\") == c).mean().alias(f\"{c}_ET_mean_{feature_suffix}\")\n",
    "          for c in event_name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"event_name\") == c).sum().alias(f\"{c}_ET_sum_{feature_suffix}\") for\n",
    "          c in event_name_feature],\n",
    "\n",
    "        *[pl.col(\"name\").filter(pl.col(\"name\") == c).count().alias(f\"{c}_name_counts{feature_suffix}\") for c in\n",
    "          name_feature],\n",
    "        # *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"name\") == c).std().alias(f\"{c}_ET_std_{feature_suffix}\") for c in\n",
    "        #   name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"name\") == c).mean().alias(f\"{c}_ET_mean_{feature_suffix}\") for c in\n",
    "          name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"name\") == c).sum().alias(f\"{c}_ET_sum_{feature_suffix}\") for c in\n",
    "          name_feature],\n",
    "\n",
    "        *[pl.col(\"level\").filter(pl.col(\"level\") == c).count().alias(f\"{c}_LEVEL_count{feature_suffix}\") for c in\n",
    "          LEVELS],\n",
    "        # *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level\") == c).std().alias(f\"{c}_ET_std_{feature_suffix}\") for c in\n",
    "        #   LEVELS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level\") == c).mean().alias(f\"{c}_ET_mean_{feature_suffix}\") for c\n",
    "          in\n",
    "          LEVELS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level\") == c).sum().alias(f\"{c}_ET_sum_{feature_suffix}\") for c in\n",
    "          LEVELS],\n",
    "\n",
    "        *[pl.col(\"level_group\").filter(pl.col(\"level_group\") == c).count().alias(\n",
    "            f\"{c}_LEVEL_group_count{feature_suffix}\") for c in\n",
    "          level_groups],\n",
    "        # *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level_group\") == c).std().alias(f\"{c}_ET_std_{feature_suffix}\") for\n",
    "        #   c in\n",
    "        #   level_groups],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level_group\") == c).mean().alias(f\"{c}_ET_mean_{feature_suffix}\")\n",
    "          for c in\n",
    "          level_groups],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level_group\") == c).sum().alias(f\"{c}_ET_sum_{feature_suffix}\") for\n",
    "          c in level_groups],\n",
    "\n",
    "        *[pl.col(\"index\").filter((pl.col(\"level\") == c) & (pl.col('room_fqid') == d)).count().alias(\n",
    "            f\"{c}{d}_level_room_count{feature_suffix}\") for c in LEVELS for d in room_lists],\n",
    "\n",
    "        # 신규 생성\n",
    "        *[pl.col(\"index\").filter((pl.col(\"event_type\") == c) & (pl.col('room_fqid') == d)).count().alias(\n",
    "            f\"{c}_{d}_event_type_room_count{feature_suffix}\") for c in event_type for d in room_lists],\n",
    "\n",
    "        # 신규 생성\n",
    "        *[pl.col(\"index\").filter((pl.col(\"event_name\") == c) & (pl.col('room_fqid') == d)).count().alias(\n",
    "            f\"{c}_{d}_event_room_count{feature_suffix}\") for c in event_name_feature for d in room_lists],\n",
    "\n",
    "        # 신규 생성 (모델 적용 전)\n",
    "        *[pl.col(\"elapsed_time_diff\").filter((pl.col(\"event_type\") == c) & (pl.col('room_fqid') == d)).mean().alias(\n",
    "            f\"{c}_{d}_event_type_room_time{feature_suffix}\") for c in event_type for d in room_lists],\n",
    "\n",
    "        # 신규 생성 (모델 적용 전)\n",
    "        *[pl.col(\"elapsed_time_diff\").filter((pl.col(\"event_name\") == c) & (pl.col('room_fqid') == d)).mean().alias(\n",
    "            f\"{c}_{d}_event_room_time{feature_suffix}\") for c in event_name_feature for d in room_lists],\n",
    "\n",
    "    ]\n",
    "    x = x.with_columns(pl.when(col('event_name').str.contains('click|checkpoint')\n",
    "                               ).then('click').otherwise('hover').alias('event_type'))\n",
    "\n",
    "    df = x.groupby(['session_id'], maintain_order=True).agg(\n",
    "        aggs).sort(\"session_id\")\n",
    "\n",
    "    df = df.to_pandas()\n",
    "    # 신규 생성\n",
    "    for c in total_event:\n",
    "      for d in event_type:\n",
    "        df[f'timediff_per_{d}_{c}'] = df[f'{c}_ET_sum_{feature_suffix}'] / \\\n",
    "            df[f\"{d}_type_counts{feature_suffix}\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def time_feature(train):\n",
    "    train[\"month\"] = train[\"session_id\"].apply(\n",
    "        lambda x: int(str(x)[2:4])+1).astype(np.uint8)\n",
    "    train[\"day\"] = train[\"session_id\"].apply(\n",
    "        lambda x: int(str(x)[4:6])).astype(np.uint8)\n",
    "    train[\"hour\"] = train[\"session_id\"].apply(\n",
    "        lambda x: int(str(x)[6:8])).astype(np.uint8)\n",
    "\n",
    "    return train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = feature_engineer(df1, grp='0-4', use_extra=True, feature_suffix='')\n",
    "df2 = feature_engineer(df2, grp='5-12', use_extra=True, feature_suffix='')\n",
    "df3 = feature_engineer(df3, grp='13-22', use_extra=True, feature_suffix='')\n",
    "\n",
    "df1 = time_feature(df1)\n",
    "df2 = time_feature(df2)\n",
    "df3 = time_feature(df3)\n",
    "\n",
    "null1 = df1.isnull().sum().sort_values(ascending=False)/len(df1)\n",
    "null2 = df2.isnull().sum().sort_values(ascending=False)/len(df2)\n",
    "null3 = df3.isnull().sum().sort_values(ascending=False)/len(df3)\n",
    "\n",
    "drop1 = list(null1[null1 > 0.9].index)\n",
    "drop2 = list(null2[null2 > 0.9].index)\n",
    "drop3 = list(null3[null3 > 0.9].index)\n",
    "\n",
    "print(len(drop1), len(drop2), len(drop3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in tqdm(df1.columns):\n",
    "    if df1[col].nunique() == 1:\n",
    "        print(col)\n",
    "        drop1.append(col)\n",
    "for col in tqdm(df2.columns):\n",
    "    if df2[col].nunique() == 1:\n",
    "        print(col)\n",
    "        drop2.append(col)\n",
    "for col in tqdm(df3.columns):\n",
    "    if df3[col].nunique() == 1:\n",
    "        print(col)\n",
    "        drop3.append(col)\n",
    "\n",
    "df1 = df1.set_index('session_id')\n",
    "df2 = df2.set_index('session_id')\n",
    "df3 = df3.set_index('session_id')\n",
    "\n",
    "\n",
    "FEATURES1 = [c for c in df1.columns if c not in drop1+['level_group']]\n",
    "FEATURES2 = [c for c in df2.columns if c not in drop2+['level_group']]\n",
    "FEATURES3 = [c for c in df3.columns if c not in drop3+['level_group']]\n",
    "print('We will train with', len(FEATURES1), len(\n",
    "    FEATURES2), len(FEATURES3), 'features')\n",
    "ALL_USERS = df1.index.unique()\n",
    "print('We will train with', len(ALL_USERS), 'users info')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = targets.set_index('session')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dic = {}\n",
    "for q in tqdm(range(1, 19)):\n",
    "    col_ls = []\n",
    "    if q <= 3:\n",
    "        grp = '0-4'\n",
    "        df = df1\n",
    "        FEATURES = FEATURES1\n",
    "    elif q <= 13:\n",
    "        grp = '5-12'\n",
    "        df = df2\n",
    "        FEATURES = FEATURES2\n",
    "    elif q <= 22:\n",
    "        grp = '13-22'\n",
    "        df = df3\n",
    "        FEATURES = FEATURES3\n",
    "    for c in FEATURES:\n",
    "        if len(df[c].unique()) == 1:\n",
    "            pass\n",
    "        elif len(df[c].unique()) == 2:\n",
    "            p_value = stats.chi2_contingency(pd.crosstab(df[c], targets.loc[(\n",
    "                targets.q == q) & (targets.index.isin(df.index)), :]['correct']))[1]\n",
    "            if p_value < 0.05:\n",
    "                col_ls.append(c)\n",
    "        else:\n",
    "            idx1 = targets.loc[(targets.q == q) & (\n",
    "                targets.correct == 1), :].index\n",
    "            idx0 = targets.loc[(targets.q == q) & (\n",
    "                targets.correct == 0), :].index\n",
    "\n",
    "            p_value1 = stats.ttest_ind(df.loc[df.index.isin(\n",
    "                idx1)][c], df.loc[df.index.isin(idx0)][c])[1]\n",
    "            if p_value1 < 0.05:\n",
    "                col_ls.append(c)\n",
    "    col_dic[f'question_{q}'] = col_ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
